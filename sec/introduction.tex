\section{Introduction}
\label{ch:introduction}

\textit{Two plus two is}... four. That is presumably one of the most likely ways that a human would continue this sentence. OpenAI's most recent text generator, though, has other answers in mind:
\begin{quote}
	...a three, five is a six, seven... \\
	...the result of a simple equation, and the... \\
	...four, and two plus three is four...
\end{quote}
These answers were generated by what 

Paper~\footcite{hovy-spruit-2016-social} ``The social impact of natural language processing'' -> says that people should not over-dramatize artificial text generation.

Website~\footnote{\url{https://medium.com/1st-draft/fake-news-its-complicated-d0f773766c79}} that argues that direct spread (one-to-one) of fake news is more dangerous than one-to-many news because if one person shares their contacts believe it to be more reliable (says that this is more dangerous than profit-driven macedonian teenagers).

The verge article~\footnote{\url{https://www.theverge.com/2019/11/7/20953040/openai-text-generation-ai-gpt-2-full-model-release-1-5b-parameters}}: “The words ‘too dangerous’ were casually thrown out here without a lot of thought or experimentation,” researcher Delip Rao told The Verge back in February. “I don’t think [OpenAI] spent enough time proving it was actually dangerous.”

Lex Friedman video: 

Talk about Huggingface? \\
Sebastian Ruder NLP progress \\
XLnet ourpterforms BERT on 20 tasks, often by a large margin. -> achieved sota performance on 18 NLP tasks including question answering, natural language inference, sentiment analysis and document ranking \\
How much do transformers understand? transformers learn by statistical facts in a self-supervised way \\
Transformers are FAR from understanding language (for now) \\
INPUT: Two plus two is \\
Answer 1: a three, five is a six, seven \\
Answer 2: the result of a simple equation, and the \\
Answer 3: four, and two plus three is four \\

Thesis Topic

Detection of synthetically generated text \\
Problem: Synthetic text generators like OpenAI’s GPT-2 are already capable of creating text that is hardly distinguishable from human-created text. As these generators are open-source they are prone to be misused, e.g., for propaganda purposes. \\
Goal: Provide an overview of existing detection mechanisms and prototypically implement extensions for improving these models (e.g., additional meta-data). \\
Data: Generated text from GPT-2 and collected human texts