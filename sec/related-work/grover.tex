\subsubsection{Grover}
\label{sub:grover}

In their paper~\footcite{zellers2019neuralfakenews} the authors present a model for controllable text generation called \textbf{Grover}. This model can generate article-like texts when prompted with a headline like `Why Bitcoin is a great investment' (figure~\ref{fig:grover}).

\begin{figure}[h]
  	\includegraphics[height=7cm]{img/grover_fake_article}
  	\caption{Fake article excerpt, written by Grover}
	\label{fig:grover}
\end{figure}

This means, Grover was specifically designed to write articles - these have a necessary structure beyond the pure text (the body field). Other fields include the domain of the article and relating thereto to its writing style, the date of the publication, the names of the authors and the headline. In this sense, an article can be modeled by the joint distribution
\begin{equation}
	p(\text{domain}, \text{date}, \text{authors}, \text{headline}, \text{body}).
\end{equation}
As for the architecture, Grover uses the same one as \gls{gpt2} and comes in three different versions: Grover-Base with 124 million parameters, Grover-Large with 355 million parameters and Grover-Mega with 1.5 billion parameters. Grover was trained on the dataset `RealNews' which was introduced and created by the authors and consists of a large corpus of news articles from Common Crawl~\footnote{\url{https://commoncrawl.org/}} - being 120GB of size after deduplication. With the use of 256 TPU v3 cores, the training time was two weeks. \\
Because most human-written articles found online are from the distant past, articles to be detected will likely be set in the present, which is why the authors frame neural fake news detection as a semi-supervised problem. To test the quality of generated articles, entries were split into four different categories: human-written articles from reputable news websites (short: `\textit{Human News}'), Grover-written articles conditioned on the same metadata (short: `\textit{Machine News}'), human-written articles from known propaganda websites~\footnote{\url{breitbart.com}, \url{infowars.com}, \url{wnd.com}, \url{bigleaguepolitics.com}, \url{nautralnews.com}} (short: `\textit{Human Propaganda}') and lastly Grover-written articles conditioned on the propaganda metadata (short: `\textit{Machine Propaganda}'). When asking a pool of qualified workers on \gls{mturk} to distinguish between machine and human-written text, results show that while the quality of Grover-written news is not as high as human-written news, Grover is adept at rewriting propaganda: The workers on \gls{mturk} rated the trustworthiness scores of Grover propaganda higher than that of human propaganda. Talking about future progress in discrimination, the authors say that their discriminators are effective, but they have the limitation that they rely primarily on distributional features of the content rather than evidence. They argue that in contrast, humans assess whether an article is truthful by relying on a model of the world, revising whether the evidence in the article matches that model. That is why future work should investigate integrating knowledge into the discriminator.
